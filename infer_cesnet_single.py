import numpy as np
import logging
import torch
import pandas as pd

from time import time
from torch.utils.data import DataLoader
from config.config import Config
from dataset.Dataset import Dataset
from temporal_fusion_transformer import TemporalFusionTransformer
from utils import (
    QuantileLoss, symmetric_mean_absolute_percentage_error,
    unnormalize_tensor, plot_temporal_serie
)
from dataset.traffic_data_formatter import TrafficDataFormatter
from dataset.Dataset_cesnet import CESNETDataset


class InferenceSingleStep:
    """
    Class for loading and testing the pre-trained model
    """

    def __init__(self, cnf):
        self.cnf = cnf
        test_path = r"D:\PythonProject\chatbot\dataset\preprocessed\CESNET\val.csv"

        # âœ… åŠ è½½æµ‹è¯•æ•°æ®
        self.dataset_test = CESNETDataset(test_path)
        self.formatter = TrafficDataFormatter(
            scaler_path=r"D:\PythonProject\chatbot\dataset\preprocessed\CESNET\scaler.save")

        # âœ… è®¾å¤‡é€‰æ‹©
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # âœ… è‡ªåŠ¨è®¾ç½® input_size
        input_dim = self.dataset_test.inputs.shape[-1]
        self.cnf.all_params["input_size"] = input_dim
        self.cnf.all_params["input_obs_loc"] = self.dataset_test.input_obs_loc

        # âœ… åˆå§‹åŒ–æ¨¡å‹
        self.model = TemporalFusionTransformer(self.cnf.all_params).to(self.device)

        # âœ… è¯»å–æœ€ä¼˜æ¨¡å‹æƒé‡
        self.load_checkpoint()

        # âœ… åˆå§‹åŒ–æµ‹è¯• DataLoader
        self.test_loader = DataLoader(
            dataset=self.dataset_test, batch_size=cnf.batch_size,
            num_workers=cnf.n_workers, shuffle=False, pin_memory=True
        )

        # âœ… åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self.loss = QuantileLoss(cnf.quantiles)

        # âœ… è®°å½•æ—¥å¿—
        self.log_file = self.cnf.exp_log_path / "inference_log.txt"
        logging.basicConfig(
            filename=self.log_file,
            filemode="a",
            format="%(asctime)s - %(levelname)s - %(message)s",
            level=logging.INFO
        )

    def load_checkpoint(self):
        from pathlib import Path
        """åŠ è½½æœ€ä½³æ¨¡å‹"""
        # ck_path = self.cnf.exp_log_path / f"{self.cnf.exp_name}_best.pth"
        ck_path = Path(r"D:\PythonProject\chatbot\log\CESNET\03-25-2025-21-34-44\epoch_16.pth")
        if ck_path.exists():
            checkpoint = torch.load(ck_path, map_location='cuda', weights_only=False)
            self.model.load_state_dict(checkpoint['model'])
            # self.model.load_state_dict(torch.load(ck_path,weights_only=False))
            print(f"[Loaded best model from '{ck_path}']")
        else:
            raise FileNotFoundError(f"Checkpoint '{ck_path}' not found!")

    def inverse_transform(self, arr):
        """å°†æ ‡å‡†åŒ–çš„æ•°æ®è½¬æ¢å›åŸå§‹å°ºåº¦"""
        # ç¡®ä¿è¾“å…¥æ˜¯CPUå¼ é‡
        if isinstance(arr, torch.Tensor):
            if arr.is_cuda:
                arr = arr.cpu()  # ä»GPUç§»åˆ°CPU
            arr = arr.numpy()

        # å‡è®¾ç›®æ ‡åˆ—æ˜¯ç¬¬0åˆ—
        target_col = 0

        # åˆ›å»ºdummyæ•°ç»„æ¥æ‰§è¡Œinverse_transform
        dummy = np.zeros((arr.shape[0], self.formatter.scaler.scale_.shape[0]))
        dummy[:, target_col] = arr[:, 0]  # ç°åœ¨arrå·²ç»æ˜¯numpyæ•°ç»„

        inv = self.formatter.scaler.inverse_transform(dummy)[:, target_col]
        return np.expm1(inv)





    def visualize_attention(self, attention, components):
        """å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡"""
        import matplotlib.pyplot as plt
        import seaborn as sns
        import os

        # åˆ›å»ºä¿å­˜å›¾åƒçš„ç›®å½•
        save_dir = self.cnf.exp_log_path / "attention_viz"
        os.makedirs(save_dir, exist_ok=True)

        # æå–æ³¨æ„åŠ›æƒé‡
        temporal_attention = attention[0].cpu().numpy().squeeze()  # [æ—¶é—´æ­¥, æ—¶é—´æ­¥]
        variable_attention = attention[1].cpu().numpy().squeeze()  # [å˜é‡æ•°]

        # è·å–å˜é‡åç§°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        variable_names = getattr(self.dataset_test, 'feature_names',
                                 [f"ç‰¹å¾{i}" for i in range(variable_attention.shape[0])])

        # 1. ç»˜åˆ¶æ—¶é—´æ³¨æ„åŠ›çƒ­å›¾
        plt.figure(figsize=(10, 8))
        sns.heatmap(temporal_attention, cmap='viridis', annot=False)
        plt.title('æ—¶é—´æ­¥æ³¨æ„åŠ›åˆ†å¸ƒ')
        plt.xlabel('ç›®æ ‡æ—¶é—´æ­¥')
        plt.ylabel('æºæ—¶é—´æ­¥')
        plt.tight_layout()
        plt.savefig(save_dir / "temporal_attention.png")
        plt.close()

        # 2. ç»˜åˆ¶å˜é‡æ³¨æ„åŠ›æ¡å½¢å›¾
        plt.figure(figsize=(12, 6))
        plt.bar(variable_names, variable_attention)
        plt.title('å˜é‡é‡è¦æ€§åˆ†å¸ƒ')
        plt.xlabel('ç‰¹å¾')
        plt.ylabel('æ³¨æ„åŠ›æƒé‡')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(save_dir / "variable_attention.png")
        plt.close()

        print(f"æ³¨æ„åŠ›å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {save_dir}")

    def run_inference_single_step(self):
        """
        è¿è¡Œå•æ­¥é¢„æµ‹ - å¯¹æ¯ä¸ªæ ·æœ¬åªé¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥
        ä¸è¿›è¡Œé€’æ¨é¢„æµ‹ï¼Œåªä½¿ç”¨æ¨¡å‹ç¼–ç å™¨éƒ¨åˆ†ç¼–ç å›ºå®šçš„æ—¶é—´çª—å£(num_encoder_steps)
        """
        try:
            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.eval()

            # å­˜å‚¨æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®å€¼
            all_preds = []
            all_trues = []

            total_steps = len(self.dataset_test)
            print(f"ğŸš€ å¼€å§‹å•æ­¥é¢„æµ‹ï¼Œæ€»å…± {total_steps} æ¡è®°å½•")

            with torch.no_grad():
                for idx in range(total_steps):
                    try:
                        # è·å–ä¸€ä¸ªæ ·æœ¬
                        sample = self.dataset_test[idx]

                        # å‡†å¤‡è¾“å…¥æ•°æ® - å·²ç»åŒ…å«äº†å›ºå®šçš„ç¼–ç å™¨æ—¶é—´çª—å£
                        x = sample['inputs'].unsqueeze(0).to(self.device)  # shape: [1, input_len, feature_dim]

                        # æ‰§è¡Œæ¨¡å‹é¢„æµ‹ï¼Œå¤„ç†å¯èƒ½çš„é”™è¯¯
                        try:
                            # å¯¹å½“å‰æ—¶é—´çª—å£é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥
                            out, _, _ = self.model(x)
                            pred = out[0, -1, 1].cpu().numpy()  # ä¸­ä½æ•°é¢„æµ‹
                        except RuntimeError as e:
                            if "stack expects each tensor to be equal size" in str(e):
                                print(f"æ ·æœ¬ {idx} å¤„ç†å¤±è´¥ï¼Œè·³è¿‡: {e}")
                                continue
                            else:
                                raise e

                        # è·å–çœŸå®å€¼
                        y_true = sample['outputs'][0, 0].item()

                        # ä¿å­˜é¢„æµ‹å’ŒçœŸå®å€¼
                        all_preds.append(pred)
                        all_trues.append(y_true)

                        # æ‰“å°è¿›åº¦
                        if idx % 100 == 0 or idx == total_steps - 1:
                            print(f"[{idx + 1}/{total_steps}] Pred: {pred:.4f}, True: {y_true:.4f}")
                    except Exception as e:
                        print(f"å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                        continue  # è·³è¿‡æœ‰é—®é¢˜çš„æ ·æœ¬

                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆé¢„æµ‹
                if len(all_preds) == 0:
                    print("æ²¡æœ‰æˆåŠŸçš„é¢„æµ‹ï¼Œæ— æ³•ç»§ç»­è®¡ç®—æŒ‡æ ‡")
                    return

                # è½¬æ¢ä¸ºå¼ é‡å¹¶æ·»åŠ ç»´åº¦
                pred_tensor = torch.tensor(all_preds).unsqueeze(1)
                true_tensor = torch.tensor(all_trues).unsqueeze(1)

                # åå½’ä¸€åŒ–æ•°æ®
                try:
                    pred_inv = self.inverse_transform(pred_tensor)
                    true_inv = self.inverse_transform(true_tensor)
                except Exception as e:
                    print(f"åå½’ä¸€åŒ–å¤±è´¥: {e}")
                    # å¦‚æœåå½’ä¸€åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å€¼
                    pred_inv = pred_tensor.numpy()
                    true_inv = true_tensor.numpy()

                # è®¡ç®—å’Œæ‰“å°æŒ‡æ ‡
                self.calculate_metrics(pred_inv, true_inv)

                # å¯è§†åŒ–ç»“æœ
                self.visualize_results(true_inv, pred_inv)

                return pred_inv, true_inv

        except Exception as e:
            print(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None, None

    def calculate_metrics(self, pred_inv, true_inv):
        """è®¡ç®—å’Œæ‰“å°è¯„ä¼°æŒ‡æ ‡"""
        try:
            # è®¡ç®—SMAPE
            smape = symmetric_mean_absolute_percentage_error(pred_inv, true_inv)

            # è®¡ç®—MSE
            mse = np.mean((pred_inv - true_inv) ** 2)

            # è®¡ç®—RÂ²å’ŒPearsonç›¸å…³ç³»æ•°ï¼ˆéœ€è¦å¤„ç†å¯èƒ½çš„NaNå€¼ï¼‰
            valid_mask = ~np.isnan(true_inv.flatten()) & ~np.isnan(pred_inv.flatten())
            if np.sum(valid_mask) > 1:  # è‡³å°‘éœ€è¦ä¸¤ä¸ªæœ‰æ•ˆç‚¹
                r2 = np.corrcoef(true_inv.flatten()[valid_mask], pred_inv.flatten()[valid_mask])[0, 1] ** 2
                pearson = np.corrcoef(true_inv.flatten()[valid_mask], pred_inv.flatten()[valid_mask])[0, 1]
            else:
                r2 = np.nan
                pearson = np.nan

            # è®¡ç®—å¹³å‡é¢„æµ‹/å®é™…æ¯”ç‡
            ratio = np.mean(pred_inv / true_inv)

            # æ‰“å°ç»“æœ
            print(f"\nğŸ¯ å•æ­¥é¢„æµ‹è¯„ä¼°ç»“æœ:")
            print(f"  - SMAPE: {smape:.6f}")
            print(f"  - MSE: {mse:.6f}")
            print(f"  - RÂ² Score: {r2:.6f}")
            print(f"  - Pearson Correlation: {pearson:.6f}")
            print(f"  - å¹³å‡é¢„æµ‹/å®é™…æ¯”ç‡: {ratio:.6f}")

            # è®°å½•åˆ°æ—¥å¿—
            logging.info(
                f"å•æ­¥é¢„æµ‹è¯„ä¼°ç»“æœ: SMAPE={smape:.6f}, MSE={mse:.6f}, R2={r2:.6f}, Pearson={pearson:.6f}, Ratio={ratio:.6f}")

            return {
                "smape": smape,
                "mse": mse,
                "r2": r2,
                "pearson": pearson,
                "ratio": ratio
            }
        except Exception as e:
            print(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            return None

    def visualize_results(self, true_inv, pred_inv):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        import matplotlib.pyplot as plt
        import os

        # åˆ›å»ºä¿å­˜å›¾åƒçš„ç›®å½•
        save_dir = self.cnf.exp_log_path / "visualizations"
        os.makedirs(save_dir, exist_ok=True)

        # ç»˜åˆ¶æ•´ä½“é¢„æµ‹æ›²çº¿
        plt.figure(figsize=(12, 6))
        plt.plot(true_inv.flatten(), label='True', color='blue', alpha=0.7)
        plt.plot(pred_inv.flatten(), label='Predicted', color='red', alpha=0.7)
        plt.legend()
        plt.title("True vs Predicted Values")
        plt.xlabel("Time Step")
        plt.ylabel("Value")
        plt.grid(True, alpha=0.3)

        # ä¿å­˜å›¾åƒ
        plt.tight_layout()
        plt.savefig(save_dir / "prediction_overall.png")
        plt.close()  # å…³é—­å›¾è¡¨è€Œä¸æ˜¯æ˜¾ç¤º

        # ç»˜åˆ¶éƒ¨åˆ†æ”¾å¤§å›¾ (å¦‚æœæ•°æ®ç‚¹è¶…è¿‡100ä¸ª)
        if len(true_inv) > 100:
            # é€‰æ‹©æœ€å100ä¸ªç‚¹
            plt.figure(figsize=(12, 6))
            plt.plot(true_inv.flatten()[-100:], label='True', color='blue')
            plt.plot(pred_inv.flatten()[-100:], label='Predicted', color='red')
            plt.legend()
            plt.title("True vs Predicted (Last 100 Points)")
            plt.xlabel("Time Step")
            plt.ylabel("Value")
            plt.grid(True, alpha=0.3)

            # ä¿å­˜å›¾åƒ
            plt.tight_layout()
            plt.savefig(save_dir / "prediction_last_100.png")
            plt.close()  # å…³é—­å›¾è¡¨è€Œä¸æ˜¯æ˜¾ç¤º

        # ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒ
        plt.figure(figsize=(10, 6))
        errors = pred_inv.flatten() - true_inv.flatten()
        plt.hist(errors, bins=50, alpha=0.7, color='blue')
        plt.title("Prediction Error Distribution")
        plt.xlabel("Error")
        plt.ylabel("Frequency")
        plt.grid(True, alpha=0.3)

        # ä¿å­˜å›¾åƒ
        plt.tight_layout()
        plt.savefig(save_dir / "error_distribution.png")
        plt.close()  # å…³é—­å›¾è¡¨è€Œä¸æ˜¯æ˜¾ç¤º

        # ç»˜åˆ¶æ•£ç‚¹å›¾
        plt.figure(figsize=(8, 8))
        plt.scatter(true_inv.flatten(), pred_inv.flatten(), alpha=0.5)
        plt.plot([true_inv.min(), true_inv.max()], [true_inv.min(), true_inv.max()], 'r--')
        plt.title("True vs Predicted Scatter Plot")
        plt.xlabel("True Values")
        plt.ylabel("Predicted Values")
        plt.grid(True, alpha=0.3)

        # ä¿å­˜å›¾åƒ
        plt.tight_layout()
        plt.savefig(save_dir / "scatter_plot.png")
        plt.close()  # å…³é—­å›¾è¡¨è€Œä¸æ˜¯æ˜¾ç¤º

        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {save_dir}")


if __name__ == "__main__":
    from config.config_infer import Config  # ç¡®ä¿ config è·¯å¾„æ­£ç¡®

    # åˆå§‹åŒ–é…ç½®
    cnf = Config(conf_file_path=r"D:\PythonProject\chatbot\config\config\CESNET.yaml", exp_name="CESNET")
    inference = Inference(cnf)

    # è¿è¡Œå•æ­¥é¢„æµ‹ï¼ˆä½¿ç”¨å›ºå®šçš„ç¼–ç å™¨æ—¶é—´çª—å£ï¼‰
    print("\n=== è¿è¡Œå•æ­¥é¢„æµ‹ ===")
    print(f"ä½¿ç”¨ç¼–ç å™¨æ—¶é—´çª—å£: {cnf.all_params.get('num_encoder_steps', 48)} æ­¥")

    # æ‰§è¡Œå•æ­¥é¢„æµ‹
    pred_inv, true_inv = inference.run_inference_single_step()

    # å¦‚æœæˆåŠŸå®Œæˆé¢„æµ‹ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–åˆ†æ
    if pred_inv is not None and true_inv is not None:
        print("é¢„æµ‹å®Œæˆ âœ…")

        # è®¡ç®—å¹¶æ‰“å°é«˜ä¼°ä½ä¼°æ ·æœ¬çš„æ¯”ä¾‹
        over_estim_count = np.sum(pred_inv > true_inv)
        under_estim_count = np.sum(pred_inv < true_inv)
        total = len(pred_inv)

        print(f"\nğŸ“Š é¢„æµ‹åå·®åˆ†æ:")
        print(f"  - é«˜ä¼°æ ·æœ¬æ•°é‡: {over_estim_count} ({over_estim_count / total * 100:.1f}%)")
        print(f"  - ä½ä¼°æ ·æœ¬æ•°é‡: {under_estim_count} ({under_estim_count / total * 100:.1f}%)")
        print(f"  - å‡†ç¡®æ ·æœ¬æ•°é‡: {total - over_estim_count - under_estim_count}")

        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šè‡ªå®šä¹‰åˆ†æ...
    else:
        print("é¢„æµ‹å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåç»­åˆ†æ âŒ")